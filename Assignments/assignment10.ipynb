{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Sample document\n",
    "document = \"Tokenization is the process of breaking down a document into individual words or tokens. POS tagging assigns a part of speech tag to each token. Stop words are commonly used words that are often removed. Stemming reduces words to their root or base form. Lemmatization finds the base or dictionary form of a word.\"\n",
    "\n",
    "# Tokenization\n",
    "tokens = word_tokenize(document)\n",
    "\n",
    "# POS Tagging\n",
    "pos_tags = pos_tag(tokens)\n",
    "\n",
    "# Stop words removal\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "\n",
    "# Stemming\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_tokens = [stemmer.stem(token) for token in filtered_tokens]\n",
    "\n",
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "\n",
    "# Print the results\n",
    "print(\"Original Document:\\n\", document)\n",
    "print(\"\\nTokenization:\\n\", tokens)\n",
    "print(\"\\nPOS Tagging:\\n\", pos_tags)\n",
    "print(\"\\nStop Words Removal:\\n\", filtered_tokens)\n",
    "print(\"\\nStemming:\\n\", stemmed_tokens)\n",
    "print(\"\\nLemmatization:\\n\", lemmatized_tokens)\n",
    "\n",
    "# Calculate TF-IDF representation of documents\n",
    "documents = [document]  # List of documents\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Print the TF-IDF representation\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "tfidf_representation = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n",
    "print(\"\\nTF-IDF Representation:\")\n",
    "print(tfidf_representation)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
